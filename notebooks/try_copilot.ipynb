{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a9ce1f",
   "metadata": {},
   "source": [
    "# GSPhar Model Notebook\n",
    "This notebook recreates the GSPhar model from the original `d-GSPHAR.ipynb`, including dataset utilities, model definition, training functions, and a summary display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b48cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd8ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import sqrtm, eig\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "552cb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spillover index utility (from original notebook)\n",
    "def compute_spillover_index(data, horizon, lag, scarcity_prop, standardized=True):\n",
    "    data_array = data.values\n",
    "    from statsmodels.tsa.api import VAR\n",
    "    model = VAR(data_array)\n",
    "    results = model.fit(maxlags=lag)\n",
    "    Sigma = results.sigma_u\n",
    "    A = results.orth_ma_rep(maxn=horizon-1)\n",
    "    Sigma_A = []\n",
    "    A_Sigma_A = []\n",
    "    for h in range(horizon):\n",
    "        SA = (A[h] @ Sigma @ np.linalg.inv(np.diag(np.sqrt(np.diag(Sigma)))))**2\n",
    "        Sigma_A.append(SA)\n",
    "        ASA = A[h] @ Sigma @ A[h].T\n",
    "        A_Sigma_A.append(ASA)\n",
    "    num = np.cumsum(Sigma_A, axis=0)\n",
    "    den = np.cumsum(A_Sigma_A, axis=0)\n",
    "    gfevd = np.array([num[h]/np.diag(den[h])[:,None] for h in range(horizon)])\n",
    "    if standardized:\n",
    "        gfevd = np.array([m/m.sum(axis=1,keepdims=True) for m in gfevd])\n",
    "    spill = gfevd[-1].T*100\n",
    "    df = pd.DataFrame(spill, index=results.names, columns=results.names)\n",
    "    thresh = pd.Series(df.values.flatten()).quantile(scarcity_prop)\n",
    "    df[df<thresh] = 0\n",
    "    mat = df.values; np.fill_diagonal(mat,0)\n",
    "    return mat/df.shape[0] if standardized else mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0324d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSPhar model definition\n",
    "class GSPHAR(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, filter_size, A):\n",
    "        super(GSPHAR, self).__init__()\n",
    "        self.A = torch.from_numpy(A).float()\n",
    "        self.filter_size = filter_size\n",
    "        self.conv1d_lag5 = nn.Conv1d(filter_size, filter_size, 5, groups=filter_size, bias=False)\n",
    "        nn.init.constant_(self.conv1d_lag5.weight, 1.0/5)\n",
    "        self.conv1d_lag22 = nn.Conv1d(filter_size, filter_size, 22, groups=filter_size, bias=False)\n",
    "        nn.init.constant_(self.conv1d_lag22.weight, 1.0/22)\n",
    "        self.spatial_process = nn.Sequential(\n",
    "            nn.Linear(2,16), nn.ReLU(), nn.Linear(16,16), nn.ReLU(), nn.Linear(16,1), nn.ReLU()\n",
    "        )\n",
    "        self.linear_output = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def nomalized_magnet_laplacian(self, A, q, norm=True):\n",
    "        A_s = (A + A.T)/2\n",
    "        D = np.diag(A_s.sum(axis=1))\n",
    "        theta = 2*np.pi*q*(A-A.T)\n",
    "        if norm:\n",
    "            D_inv_sqrt = sqrtm(np.linalg.inv(D))\n",
    "            L = np.eye(A_s.shape[0]) - (D_inv_sqrt @ A_s @ D_inv_sqrt)*np.exp(1j*theta)\n",
    "        else:\n",
    "            L = D - A_s*np.exp(1j*theta)\n",
    "        return L\n",
    "\n",
    "    def dynamic_magnet_Laplacian(self, A, xp, xq):\n",
    "        A_diff = (A - A.T).clamp(min=0)\n",
    "        def corr(x):\n",
    "            xm = x - x.mean(dim=2,keepdim=True)\n",
    "            cov = torch.bmm(xm, xm.transpose(1,2))/(x.shape[2]-1)\n",
    "            sd = xm.std(dim=2,unbiased=True).clamp(min=1)\n",
    "            return cov/(sd.unsqueeze(2)*sd.unsqueeze(1))\n",
    "        cp, cq = corr(xp), corr(xq)\n",
    "        W = 0.5*(cp.abs()+cq.abs())*A_diff\n",
    "        W = F.softmax(W, dim=1)\n",
    "        Udg, U = [], []\n",
    "        for i in range(W.size(0)):\n",
    "            L = self.nomalized_magnet_laplacian(W[i].cpu().numpy(),0.25)\n",
    "            vals, vecs = eig(L)\n",
    "            idx = np.argsort(vals.real)\n",
    "            Udg.append(torch.tensor(vecs.real[:,idx],dtype=torch.cfloat))\n",
    "            U.append(torch.tensor(vecs.real.T[idx],dtype=torch.cfloat))\n",
    "        return torch.stack(Udg), torch.stack(U)\n",
    "\n",
    "    def forward(self, x1, x5, x22):\n",
    "        device = x1.device\n",
    "        A = self.A.to(device)\n",
    "        Udg, U = self.dynamic_magnet_Laplacian(A, x5, x22)\n",
    "        Udg, U = Udg.to(device), U.to(device)\n",
    "        # spectral transform and conv on lag5\n",
    "        x5c = torch.complex(x5,torch.zeros_like(x5))\n",
    "        x5s = torch.matmul(Udg, x5c)\n",
    "        w5 = F.softmax(torch.exp(self.conv1d_lag5.weight),dim=-1)\n",
    "        r5 = F.conv1d(x5s.real, w5, groups=self.filter_size)\n",
    "        i5 = F.conv1d(x5s.imag, w5, groups=self.filter_size)\n",
    "        x5f = torch.complex(r5,i5).squeeze(-1)\n",
    "        # similarly for lag22\n",
    "        x22c = torch.complex(x22,torch.zeros_like(x22))\n",
    "        x22s = torch.matmul(Udg, x22c)\n",
    "        w22 = F.softmax(torch.exp(self.conv1d_lag22.weight),dim=-1)\n",
    "        r22 = F.conv1d(x22s.real, w22, groups=self.filter_size)\n",
    "        i22 = F.conv1d(x22s.imag, w22, groups=self.filter_size)\n",
    "        x22f = torch.complex(r22,i22).squeeze(-1)\n",
    "        # lag1\n",
    "        x1c = torch.complex(x1,torch.zeros_like(x1)).unsqueeze(-1)\n",
    "        x1f = torch.matmul(Udg, x1c).squeeze(-1)\n",
    "        spec = torch.stack((x1f, x5f, x22f),dim=-1)\n",
    "        yr = self.linear_output(spec.real)\n",
    "        yi = self.linear_output(spec.imag)\n",
    "        ysp = torch.complex(yr, yi)\n",
    "        yout = torch.matmul(U, ysp)\n",
    "        ystack = torch.stack((yout.real.squeeze(-1),yout.imag.squeeze(-1)),dim=-1)\n",
    "        return self.spatial_process(ystack).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bdbfb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "GSPHAR                                   [1, 24]                   [1, 24]                   648\n",
       "├─Linear: 1-1                            [1, 24, 3]                [1, 24, 1]                4\n",
       "├─Linear: 1-2                            [1, 24, 3]                [1, 24, 1]                (recursive)\n",
       "├─Sequential: 1-3                        [1, 24, 2]                [1, 24, 1]                --\n",
       "│    └─Linear: 2-1                       [1, 24, 2]                [1, 24, 16]               48\n",
       "│    └─ReLU: 2-2                         [1, 24, 16]               [1, 24, 16]               --\n",
       "│    └─Linear: 2-3                       [1, 24, 16]               [1, 24, 16]               272\n",
       "│    └─ReLU: 2-4                         [1, 24, 16]               [1, 24, 16]               --\n",
       "│    └─Linear: 2-5                       [1, 24, 16]               [1, 24, 1]                17\n",
       "│    └─ReLU: 2-6                         [1, 24, 1]                [1, 24, 1]                --\n",
       "===================================================================================================================\n",
       "Total params: 989\n",
       "Trainable params: 989\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.00\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.01\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and display summary\n",
    "filter_size=24; input_dim=3; output_dim=1\n",
    "A_eye = np.eye(filter_size)\n",
    "model = GSPHAR(input_dim,output_dim,filter_size,A_eye)\n",
    "summary(model, input_data=(torch.randn(1,filter_size),torch.randn(1,filter_size,5),torch.randn(1,filter_size,22)), col_names=[\"input_size\",\"output_size\",\"num_params\"], depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318a94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cenv_njs_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
